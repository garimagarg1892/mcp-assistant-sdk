#!/usr/bin/env node

const { Server } = require("@modelcontextprotocol/sdk/server/index.js");
const {
  StdioServerTransport,
} = require("@modelcontextprotocol/sdk/server/stdio.js");
const {
  CallToolRequestSchema,
  ListToolsRequestSchema,
} = require("@modelcontextprotocol/sdk/types.js");

// Import your existing tools
const createBucket = require("./tools/createBucket");
const deleteBucket = require("./tools/deleteBucket");
const listBuckets = require("./tools/listBuckets");
const putObject = require("./tools/putObject");
const getObject = require("./tools/getObject");
const deleteObject = require("./tools/deleteObject");

// Import new file system tools
const readFile = require("./tools/readFile");
const listDirectory = require("./tools/listDirectory");

// Import MySQL bridge tool
const exportTableToStorage = require("./tools/exportTableToStorage");

// Load environment variables
require("dotenv").config();

class S3MCPServer {
  constructor() {
    this.server = new Server(
      {
        name: "mcp-s3-assistant",
        version: "1.0.0",
      },
      {
        capabilities: {
          tools: {},
        },
      }
    );

    this.setupToolHandlers();
    this.setupErrorHandling();
  }

  setupToolHandlers() {
    // Handle tool listing
    this.server.setRequestHandler(ListToolsRequestSchema, async () => {
      return {
        tools: [
          {
            name: "create_bucket",
            description: `Create an AWS S3 bucket with intelligent parameter extraction from natural language.

üß† PARAMETER EXTRACTION INTELLIGENCE:
Analyze the user's request and extract relevant AWS S3 parameters. If the user doesn't provide a bucket name, ASK FOR IT.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- bucketName: ALWAYS REQUIRED - if not provided, ask the user for it

OPTIONAL PARAMETERS (extract if mentioned):

üîí ACCESS CONTROL:
- acl: "private" | "public-read" | "public-read-write" | "authenticated-read"
  ‚Üí Default: "private" (if no access mentioned)
  ‚Üí From: "private", "public", "public read", "authenticated", "secure"

üåç REGION MAPPING:
- locationConstraint: AWS region code
  ‚Üí Default: "us-east-1" (if no region mentioned)
  ‚Üí COMMON MAPPINGS:
    ‚Ä¢ "Europe", "EU", "Ireland" ‚Üí "eu-west-1"
    ‚Ä¢ "London", "UK" ‚Üí "eu-west-2" 
    ‚Ä¢ "Paris", "France" ‚Üí "eu-west-3"
    ‚Ä¢ "Frankfurt", "Germany" ‚Üí "eu-central-1"
    ‚Ä¢ "Virginia", "US East" ‚Üí "us-east-1"
    ‚Ä¢ "Ohio", "US East 2" ‚Üí "us-east-2"
    ‚Ä¢ "Oregon", "US West" ‚Üí "us-west-2"
    ‚Ä¢ "California", "US West 1" ‚Üí "us-west-1"
    ‚Ä¢ "Asia", "Singapore" ‚Üí "ap-southeast-1"
    ‚Ä¢ "Tokyo", "Japan" ‚Üí "ap-northeast-1"
    ‚Ä¢ "Sydney", "Australia" ‚Üí "ap-southeast-2"
    ‚Ä¢ "Canada", "Toronto" ‚Üí "ca-central-1"
  ‚Üí If ambiguous (e.g., just "Asia"), ask for clarification

üîê ADVANCED FEATURES:
- objectLockEnabledForBucket: true | false
  ‚Üí From: "object lock", "versioning", "immutable", "compliance", "retention"
  
- objectOwnership: "BucketOwnerPreferred" | "ObjectWriter" | "BucketOwnerEnforced"
  ‚Üí Default: "BucketOwnerEnforced"
  ‚Üí From: "bucket owner", "writer owns", "enforced ownership"

üéØ EXAMPLES:
"Create a private bucket called 'data-backup'" ‚Üí { bucketName: "data-backup", acl: "private" }
"Public bucket in Europe" ‚Üí ASK for bucket name first
"Secure bucket in Tokyo with object lock" ‚Üí { bucketName: "...", acl: "private", locationConstraint: "ap-northeast-1", objectLockEnabledForBucket: true }
"Create bucket in Asia" ‚Üí ASK which specific Asian region

‚ö†Ô∏è ERROR HANDLING:
- If bucket name missing: "I need a bucket name. What would you like to call this bucket?"
- If region ambiguous: "Which specific region? Available options: [list relevant regions]"
- If request unclear: "Could you clarify [specific ambiguous part]?"

Pass all extracted parameters as a flat object.`,
            inputSchema: {
              type: "object",
              properties: {
                bucketName: {
                  type: "string",
                  description:
                    "Name of the S3 bucket to create (REQUIRED - ask user if not provided)",
                },
              },
              required: ["bucketName"],
              additionalProperties: true,
            },
          },
          {
            name: "delete_bucket",
            description: `Delete an AWS S3 bucket with intelligent parameter extraction from natural language.

üß† PARAMETER EXTRACTION INTELLIGENCE:
Analyze the user's request and extract relevant AWS S3 parameters. If the user doesn't provide a bucket name, ASK FOR IT.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- bucketName: ALWAYS REQUIRED - if not provided, ask the user for it

‚ö†Ô∏è IMPORTANT NOTES:
- The bucket must be empty before it can be deleted
- This operation is irreversible
- All bucket policies, ACLs, and configurations will be permanently removed

üéØ EXAMPLES:
"Delete bucket 'old-data'" ‚Üí { bucketName: "old-data" }
"Remove the test-bucket" ‚Üí { bucketName: "test-bucket" }
"Delete my-bucket" ‚Üí { bucketName: "my-bucket" }

‚ö†Ô∏è ERROR HANDLING:
- If bucket name missing: "I need a bucket name. Which bucket would you like to delete?"
- If bucket not empty: "The bucket must be empty before it can be deleted"
- If bucket doesn't exist: "The specified bucket does not exist"

Pass all extracted parameters as a flat object.`,
            inputSchema: {
              type: "object",
              properties: {
                bucketName: {
                  type: "string",
                  description:
                    "Name of the S3 bucket to delete (REQUIRED - ask user if not provided)",
                },
              },
              required: ["bucketName"],
              additionalProperties: true,
            },
          },
          {
            name: "list_buckets",
            description: `List S3 buckets with intelligent filtering and pagination.

üß† PARAMETER EXTRACTION INTELLIGENCE:
Extract filtering and pagination parameters from natural language requests.

üìã PARAMETER MAPPING GUIDE:

OPTIONAL PARAMETERS (extract if mentioned):

üî¢ PAGINATION:
- maxBuckets: Integer (1-1000)
  ‚Üí From: "first 10 buckets", "limit to 5", "show 20 buckets"
  ‚Üí Default: All buckets if not specified

- continuationToken: String
  ‚Üí From: "continue from token", "next page", pagination context
  ‚Üí Used for paginated results

üîç FILTERING:
- prefix: String  
  ‚Üí From: "buckets starting with 'test'", "buckets beginning with 'prod'"
  ‚Üí Limits response to bucket names that begin with specified prefix

- bucketRegion: String (AWS region code)
  ‚Üí From: "buckets in Europe", "US buckets", "Asia buckets"
  ‚Üí REGION MAPPINGS (same as createBucket):
    ‚Ä¢ "Europe", "EU" ‚Üí "eu-west-1"
    ‚Ä¢ "Virginia", "US East" ‚Üí "us-east-1" 
    ‚Ä¢ "Asia", "Singapore" ‚Üí "ap-southeast-1"
    ‚Ä¢ "Tokyo", "Japan" ‚Üí "ap-northeast-1"

üéØ EXAMPLES:
"List all buckets" ‚Üí {} (no parameters)
"Show first 10 buckets" ‚Üí { maxBuckets: 10 }
"List buckets starting with 'test'" ‚Üí { prefix: "test" }
"Show buckets in Europe, limit 5" ‚Üí { bucketRegion: "eu-west-1", maxBuckets: 5 }
"Buckets beginning with 'prod' in Asia" ‚Üí { prefix: "prod", bucketRegion: "ap-southeast-1" }

‚ö†Ô∏è ERROR HANDLING:
- If region ambiguous: "Which specific region? (eu-west-1, us-east-1, ap-southeast-1, etc.)"
- If maxBuckets invalid: "MaxBuckets must be between 1 and 1000"

Pass all extracted parameters as a flat object.`,
            inputSchema: {
              type: "object",
              properties: {},
              additionalProperties: true,
            },
          },
          {
            name: "put_object",
            description: `Universal upload tool - handles direct content, single files, or entire directories!

üß† PARAMETER EXTRACTION INTELLIGENCE:
Extract upload parameters from natural language requests. This tool handles 3 scenarios automatically.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- bucketName: String - Target bucket name

UPLOAD SCENARIOS (choose one):

üî∏ SCENARIO 1: Direct Content Upload
- fileName: String - Object key/file name
- fileContent: String - Raw content (base64 for binary)

üî∏ SCENARIO 2: Single File Upload  
- filePath: String - Path to local file to upload
- s3Key: String (optional) - Custom S3 object key

üî∏ SCENARIO 3: Directory Upload (Batch)
- directoryPath: String - Path to directory to upload
- preserveStructure: Boolean - Keep folder structure (default: true)
- s3Prefix: String (optional) - Prefix for all objects
- fileExtensions: Array (optional) - Filter by extensions like [".jpg", ".pdf"]
- maxFiles: Integer (optional) - Limit files uploaded (default: 100)

OPTIONAL PARAMETERS (all scenarios):
- acl: "private" | "public-read" | "public-read-write" | "authenticated-read"
- serverSideEncryption: "AES256" | "aws:kms" | "aws:kms:dsse"
- storageClass: "STANDARD" | "STANDARD_IA" | "GLACIER" | "DEEP_ARCHIVE"
- contentType: String - MIME type (auto-detected for files)
- metadata: Object - Custom metadata key-value pairs

üéØ EXAMPLES:
"Upload hello.txt with content 'Hello World'" ‚Üí { bucketName: "my-bucket", fileName: "hello.txt", fileContent: "Hello World" }
"Upload /home/user/photo.jpg to my-bucket" ‚Üí { bucketName: "my-bucket", filePath: "/home/user/photo.jpg" }
"Upload entire photos directory with backup/ prefix" ‚Üí { bucketName: "my-bucket", directoryPath: "/home/user/photos", s3Prefix: "backup" }
"Upload only PDFs from documents folder" ‚Üí { bucketName: "my-bucket", directoryPath: "/home/user/docs", fileExtensions: [".pdf"] }

‚ú® SMART FEATURES:
- Automatic file type detection (binary vs text)
- Content-Type auto-detection from file extensions
- Directory structure preservation or flattening
- Batch upload progress tracking
- Comprehensive error handling

‚ö†Ô∏è ERROR HANDLING:
- Missing bucket: "bucketName is required"
- Invalid scenario: "Provide either fileContent+fileName, filePath, or directoryPath"
- File not found: Clear error with file path
- Batch failures: Detailed per-file error reporting

Pass all extracted parameters as a flat object.`,
            inputSchema: {
              type: "object",
              properties: {
                bucketName: {
                  type: "string",
                  description: "Target bucket name",
                },
                fileName: {
                  type: "string",
                  description: "Object key/file name (for direct content)",
                },
                fileContent: {
                  type: "string",
                  description: "File content (for direct content)",
                },
                filePath: {
                  type: "string",
                  description: "Local file path to upload",
                },
                directoryPath: {
                  type: "string",
                  description: "Local directory path to upload",
                },
                s3Key: { type: "string", description: "Custom S3 object key" },
                preserveStructure: {
                  type: "boolean",
                  description: "Keep directory structure in S3",
                },
                s3Prefix: {
                  type: "string",
                  description: "Prefix for uploaded objects",
                },
                fileExtensions: {
                  type: "array",
                  items: { type: "string" },
                  description: "Filter by file extensions",
                },
                maxFiles: {
                  type: "integer",
                  description: "Maximum files to upload",
                },
              },
              required: ["bucketName"],
              additionalProperties: true,
            },
          },
          {
            name: "get_object",
            description: `Download an object from S3 bucket with advanced options.

üß† PARAMETER EXTRACTION INTELLIGENCE:
Extract download parameters and conditions from natural language requests.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- bucketName: String - Source bucket name
- fileName: String - Object key/file name to download

OPTIONAL PARAMETERS (extract if mentioned):

üîÑ CONDITIONAL DOWNLOADS:
- ifMatch: String (ETag)
  ‚Üí From: "if ETag matches", "only if unchanged"
  
- ifModifiedSince: Date
  ‚Üí From: "if modified since", "updated after", "newer than"
  
- ifNoneMatch: String (ETag) 
  ‚Üí From: "if different", "if changed", "if ETag differs"

üìè RANGE REQUESTS:
- range: String
  ‚Üí From: "first 1000 bytes", "bytes 0-1023", "partial download"
  ‚Üí Format: "bytes=0-1023"

üîê ENCRYPTION:
- sseCustomerAlgorithm: String
  ‚Üí From: "customer encryption", "SSE-C", "AES256"
  
- versionId: String
  ‚Üí From: "specific version", "version ID", "historical version"

üìã RESPONSE MODIFICATION:
- responseCacheControl: String
  ‚Üí From: "cache control", "no-cache", "max-age"
  
- responseContentType: String
  ‚Üí From: "return as", "content type", "MIME type override"

üéØ EXAMPLES:
"Download file.txt from bucket" ‚Üí { bucketName: "...", fileName: "file.txt" }
"Get first 1000 bytes of data.bin" ‚Üí { ..., range: "bytes=0-999" }
"Download if modified since yesterday" ‚Üí { ..., ifModifiedSince: "2024-01-01" }
"Get specific version of document" ‚Üí { ..., versionId: "abc123" }

‚ö†Ô∏è ERROR HANDLING:
- Missing required params: "Need bucketName and fileName"
- Invalid range format: "Range must be 'bytes=start-end'"

Pass all extracted parameters as a flat object.`,
            inputSchema: {
              type: "object",
              properties: {
                bucketName: {
                  type: "string",
                  description: "Source bucket name",
                },
                fileName: {
                  type: "string",
                  description: "Object key/file name to download",
                },
              },
              required: ["bucketName", "fileName"],
              additionalProperties: true,
            },
          },
          {
            name: "read_file",
            description: `Read any file from the local file system with automatic type detection.

üß† PARAMETER EXTRACTION INTELLIGENCE:
Extract file reading parameters from natural language requests.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- filePath: String - Path to the file to read

üéØ EXAMPLES:
"Read the file /home/user/document.pdf" ‚Üí { filePath: "/home/user/document.pdf" }
          {
            name: "delete_object",
            description: `Delete an object from S3 bucket with versioning and governance support.

üß† PARAMETER EXTRACTION INTELLIGENCE:
Extract deletion parameters from natural language requests.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- bucketName: String - Source bucket name
- fileName: String - Object key/file name to delete

OPTIONAL PARAMETERS (extract if mentioned):

üîÑ VERSIONING:
- versionId: String
  ‚Üí From: "specific version", "version ID", "delete version"
  ‚Üí Permanently deletes a specific version

üîê ADVANCED OPTIONS:
- mfa: String
  ‚Üí From: "with MFA", "MFA delete"
  ‚Üí Format: "serial-number token-code"
  ‚Üí Required for MFA Delete enabled buckets

- bypassGovernanceRetention: Boolean
  ‚Üí From: "bypass governance", "override retention"
  ‚Üí Requires s3:BypassGovernanceRetention permission

- requestPayer: String
  ‚Üí From: "requester pays"
  ‚Üí Possible values: "requester"

- expectedBucketOwner: String
  ‚Üí From: "expected owner", "account ID"
  ‚Üí Account ID validation

üéØ EXAMPLES:
"Delete file.txt from bucket" ‚Üí { bucketName: "...", fileName: "file.txt" }
"Delete specific version of document" ‚Üí { ..., versionId: "abc123" }
"Delete with MFA" ‚Üí { ..., mfa: "serial-number token" }
"Delete bypassing governance" ‚Üí { ..., bypassGovernanceRetention: true }

‚ö†Ô∏è IMPORTANT NOTES:
- S3 delete is idempotent - success doesn't guarantee object existed
- Versioned buckets create delete markers instead of permanent deletion
- Use versionId to permanently delete a specific version
- MFA delete requires HTTPS and proper MFA configuration

üõ°Ô∏è PERMISSIONS REQUIRED:
- s3:DeleteObject - Standard delete permission
- s3:DeleteObjectVersion - For deleting specific versions
- s3:BypassGovernanceRetention - For bypassing governance mode

Pass all extracted parameters as a flat object.`,
            inputSchema: {
              type: "object",
              properties: {
                bucketName: {
                  type: "string",
                  description: "Source bucket name",
                },
                fileName: {
                  type: "string",
                  description: "Object key/file name to delete",
                },
                versionId: {
                  type: "string",
                  description: "Specific version ID to delete",
                },
                mfa: {
                  type: "string",
                  description: "MFA authentication (serial-number token-code)",
                },
                bypassGovernanceRetention: {
                  type: "boolean",
                  description: "Bypass governance retention mode",
                },
              },
              required: ["bucketName", "fileName"],
              additionalProperties: true,
            },
          },
"Show me the contents of config.json" ‚Üí { filePath: "config.json" }
"What's in that image file?" ‚Üí { filePath: "image.jpg" }

‚ú® FEATURES:
- Automatic binary/text detection
- Proper encoding handling (base64 for binary, utf8 for text)
- Content type detection from file extension
- File metadata (size, modified date, etc.)
- Support for all file types (images, documents, code, etc.)

‚ö†Ô∏è ERROR HANDLING:
- File not found: Clear error message with file path
- Permission denied: Helpful access error information
- Invalid path: Path validation and suggestions`,
            inputSchema: {
              type: "object",
              properties: {
                filePath: {
                  type: "string",
                  description: "Path to the file to read",
                },
              },
              required: ["filePath"],
              additionalProperties: true,
            },
          },
          {
            name: "list_directory",
            description: `List contents of a directory with filtering and browsing options.

üß† PARAMETER EXTRACTION INTELLIGENCE:
Extract directory listing parameters from natural language requests.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- directoryPath: String - Path to the directory to list

OPTIONAL PARAMETERS:
- showHidden: Boolean - Show hidden files/folders (default: false)
- filesOnly: Boolean - Show only files (default: false)
- dirsOnly: Boolean - Show only directories (default: false)
- recursive: Boolean - Recursive listing (default: false)
- maxDepth: Integer - Maximum depth for recursive listing (default: 3)

üéØ EXAMPLES:
"List files in /home/user/documents" ‚Üí { directoryPath: "/home/user/documents" }
"Show all files including hidden ones" ‚Üí { directoryPath: ".", showHidden: true }
"List only directories recursively" ‚Üí { directoryPath: "/path", dirsOnly: true, recursive: true }
"Browse folder structure 2 levels deep" ‚Üí { directoryPath: "/path", recursive: true, maxDepth: 2 }

‚ú® FEATURES:
- File and directory information (size, modified date, type)
- Filtering options (files only, directories only, hidden files)
- Recursive directory traversal
- Sorted output (directories first, then files)
- File extension detection

‚ö†Ô∏è ERROR HANDLING:
- Directory not found: Clear error with path
- Permission denied: Access error information
- Invalid path: Path validation`,
            inputSchema: {
              type: "object",
              properties: {
                directoryPath: {
                  type: "string",
                  description: "Path to the directory to list",
                },
                showHidden: {
                  type: "boolean",
                  description: "Show hidden files and folders",
                },
                filesOnly: { type: "boolean", description: "Show only files" },
                dirsOnly: {
                  type: "boolean",
                  description: "Show only directories",
                },
                recursive: { type: "boolean", description: "List recursively" },
                maxDepth: {
                  type: "integer",
                  description: "Maximum depth for recursive listing",
                },
              },
              required: ["directoryPath"],
              additionalProperties: true,
            },
          },
          {
            name: "export_table_to_storage",
            description: `Export MySQL table data to S3/ObjectStore via MCP bridge.

üåâ MCP BRIDGE INTELLIGENCE:
This tool connects MySQL MCP with your S3 MCP to create a seamless data pipeline.

üìã PARAMETER MAPPING GUIDE:

REQUIRED:
- tableName: String - Name of the MySQL table to export
- bucketName: String - Target S3 bucket name

MYSQL CONNECTION (optional - uses env vars if not provided):
- mysqlHost: String - MySQL server host (default: localhost)
- mysqlPort: Integer - MySQL server port (default: 3306)  
- mysqlUser: String - MySQL username (default: root)
- mysqlPassword: String - MySQL password
- mysqlDatabase: String - MySQL database name

QUERY OPTIONS (optional):
- where: String - WHERE clause for filtering data
- orderBy: String - ORDER BY clause for sorting
- limit: Integer - LIMIT number of records

OUTPUT OPTIONS (optional):
- format: "json" | "csv" | "jsonl" (default: json)
- fileName: String - Custom output filename
- prettyFormat: Boolean - Pretty print JSON (default: true)
- csvDelimiter: String - CSV delimiter (default: comma)

S3 OPTIONS (optional - same as putObject):
- s3Prefix: String - S3 object prefix
- acl: String - S3 access control
- serverSideEncryption: String - Encryption type
- storageClass: String - S3 storage class
- metadata: Object - Custom metadata

üéØ EXAMPLES:
"Export users table to my-bucket" ‚Üí { tableName: "users", bucketName: "my-bucket" }
"Export products as CSV to backup-bucket" ‚Üí { tableName: "products", bucketName: "backup-bucket", format: "csv" }
"Export recent orders to archive" ‚Üí { tableName: "orders", bucketName: "archive", where: "created_date > '2024-01-01'" }

‚ú® FEATURES:
- Automatic MySQL MCP communication
- Multiple export formats (JSON, CSV, JSONL)
- Query filtering and sorting
- Seamless S3 upload via existing putObject
- Comprehensive metadata tracking

‚ö†Ô∏è REQUIREMENTS:
- MySQL MCP server must be installed and accessible
- Valid MySQL connection parameters (via env or params)
- Target S3 bucket must exist

Pass all extracted parameters as a flat object.`,
            inputSchema: {
              type: "object",
              properties: {
                tableName: {
                  type: "string",
                  description: "MySQL table name to export",
                },
                bucketName: {
                  type: "string",
                  description: "Target S3 bucket name",
                },
                mysqlHost: { type: "string", description: "MySQL server host" },
                mysqlPort: {
                  type: "integer",
                  description: "MySQL server port",
                },
                mysqlUser: { type: "string", description: "MySQL username" },
                mysqlPassword: {
                  type: "string",
                  description: "MySQL password",
                },
                mysqlDatabase: {
                  type: "string",
                  description: "MySQL database name",
                },
                where: {
                  type: "string",
                  description: "WHERE clause for filtering",
                },
                orderBy: { type: "string", description: "ORDER BY clause" },
                limit: {
                  type: "integer",
                  description: "LIMIT number of records",
                },
                format: {
                  type: "string",
                  description: "Output format (json, csv, jsonl)",
                },
                fileName: {
                  type: "string",
                  description: "Custom output filename",
                },
                s3Prefix: { type: "string", description: "S3 object prefix" },
              },
              required: ["tableName", "bucketName"],
              additionalProperties: true,
            },
          },
        ],
      };
    });

    // Handle tool execution
    this.server.setRequestHandler(CallToolRequestSchema, async (request) => {
      const { name, arguments: args } = request.params;

      try {
        let result;

        switch (name) {
          case "create_bucket":
            // Pass ALL arguments directly to the tool - truly generic!
            result = await createBucket(args);
            break;

          case "delete_bucket":
            // Pass ALL arguments directly to the tool - truly generic!
            result = await deleteBucket(args);
            break;

          case "list_buckets":
            // Pass ALL arguments directly to the tool - truly generic!
            result = await listBuckets(args);
            break;

          case "put_object":
            // Pass ALL arguments directly to the tool - truly generic!
            result = await putObject(args);
            break;

          case "get_object":
            // Pass ALL arguments directly to the tool - truly generic!
            result = await getObject(args);
            break;


          case "delete_object":
            // Pass ALL arguments directly to the tool - truly generic!
            result = await deleteObject(args);
            break;
          case "read_file":
            // File system tool - read any file type
            result = await readFile(args);
            break;

          case "list_directory":
            // File system tool - browse directories
            result = await listDirectory(args);
            break;

          case "export_table_to_storage":
            // MySQL MCP bridge tool - export table data to S3
            result = await exportTableToStorage(args);
            break;

          default:
            throw new Error(`Unknown tool: ${name}`);
        }

        return {
          content: [
            {
              type: "text",
              text: JSON.stringify(result, null, 2),
            },
          ],
        };
      } catch (error) {
        return {
          content: [
            {
              type: "text",
              text: `Error executing ${name}: ${error.message}`,
            },
          ],
          isError: true,
        };
      }
    });
  }

  setupErrorHandling() {
    this.server.onerror = (error) => {
      console.error("[MCP Server Error]", error);
    };

    process.on("SIGINT", async () => {
      await this.server.close();
      process.exit(0);
    });
  }

  async run() {
    const transport = new StdioServerTransport();
    await this.server.connect(transport);
    console.error("MCP S3 Assistant Server running on stdio");
  }
}

// Start the server
if (require.main === module) {
  const server = new S3MCPServer();
  server.run().catch((error) => {
    console.error("Failed to start server:", error);
    process.exit(1);
  });
}

module.exports = S3MCPServer;
